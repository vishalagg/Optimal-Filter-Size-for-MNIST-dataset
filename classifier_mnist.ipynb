{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 398s   \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhLB/wOA2s4TjzPBwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1de1e208860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of images as baseline for comparison \n",
    "from keras.datasets import mnist \n",
    "from matplotlib import pyplot \n",
    "# load data \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
    "# create a grid of 3x3 images \n",
    "for i in range(0, 9): \n",
    "    pyplot.subplot(330 + 1 + i) \n",
    "    pyplot.imshow(X_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 258s - loss: 0.2311 - acc: 0.9344 - val_loss: 0.0829 - val_acc: 0.9741\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 248s - loss: 0.0738 - acc: 0.9780 - val_loss: 0.0464 - val_acc: 0.9840\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 271s - loss: 0.0534 - acc: 0.9839 - val_loss: 0.0432 - val_acc: 0.9856\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 273s - loss: 0.0403 - acc: 0.9878 - val_loss: 0.0414 - val_acc: 0.9860\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 332s - loss: 0.0339 - acc: 0.9892 - val_loss: 0.0344 - val_acc: 0.9885\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 347s - loss: 0.0276 - acc: 0.9914 - val_loss: 0.0308 - val_acc: 0.9897\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 315s - loss: 0.0234 - acc: 0.9927 - val_loss: 0.0348 - val_acc: 0.9882\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 297s - loss: 0.0207 - acc: 0.9935 - val_loss: 0.0322 - val_acc: 0.9893\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 289s - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0300 - val_acc: 0.9899\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 298s - loss: 0.0143 - acc: 0.9957 - val_loss: 0.0304 - val_acc: 0.9901\n",
      "CNN Error: 0.99%\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN \n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# fix dimension ordering issue\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define a simple CNN model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 221s - loss: 0.2491 - acc: 0.9284 - val_loss: 0.0803 - val_acc: 0.9763\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 219s - loss: 0.0756 - acc: 0.9771 - val_loss: 0.0461 - val_acc: 0.9845\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 194s - loss: 0.0521 - acc: 0.9842 - val_loss: 0.0393 - val_acc: 0.9876\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 185s - loss: 0.0426 - acc: 0.9865 - val_loss: 0.0369 - val_acc: 0.9876\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 200s - loss: 0.0340 - acc: 0.9892 - val_loss: 0.0319 - val_acc: 0.9902\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 196s - loss: 0.0293 - acc: 0.9907 - val_loss: 0.0351 - val_acc: 0.9892\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 183s - loss: 0.0262 - acc: 0.9916 - val_loss: 0.0333 - val_acc: 0.9892\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 188s - loss: 0.0220 - acc: 0.9928 - val_loss: 0.0288 - val_acc: 0.9904\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 178s - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0287 - val_acc: 0.9906\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 179s - loss: 0.0165 - acc: 0.9947 - val_loss: 0.0288 - val_acc: 0.9904\n",
      "CNN Error: 0.96%\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN \n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# fix dimension ordering issue\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define a simple CNN model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (11, 11), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 231s - loss: 0.2259 - acc: 0.9355 - val_loss: 0.0717 - val_acc: 0.9786\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 226s - loss: 0.0683 - acc: 0.9796 - val_loss: 0.0450 - val_acc: 0.9849\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 225s - loss: 0.0490 - acc: 0.9850 - val_loss: 0.0397 - val_acc: 0.9884\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 226s - loss: 0.0381 - acc: 0.9880 - val_loss: 0.0388 - val_acc: 0.9873\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 226s - loss: 0.0319 - acc: 0.9899 - val_loss: 0.0314 - val_acc: 0.9894\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 229s - loss: 0.0252 - acc: 0.9921 - val_loss: 0.0298 - val_acc: 0.9901\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 225s - loss: 0.0217 - acc: 0.9933 - val_loss: 0.0300 - val_acc: 0.9897\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 225s - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0264 - val_acc: 0.9908\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 228s - loss: 0.0153 - acc: 0.9953 - val_loss: 0.0245 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 225s - loss: 0.0127 - acc: 0.9957 - val_loss: 0.0270 - val_acc: 0.9918\n",
      "CNN Error: 0.82%\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN \n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# fix dimension ordering issue\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define a simple CNN model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (7,7), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.5845 - acc: 0.8265 - val_loss: 0.2245 - val_acc: 0.9339\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.2613 - acc: 0.9236 - val_loss: 0.1561 - val_acc: 0.9534\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.2148 - acc: 0.9354 - val_loss: 0.1328 - val_acc: 0.9607\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1881 - acc: 0.9436 - val_loss: 0.1209 - val_acc: 0.9642\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1678 - acc: 0.9484 - val_loss: 0.1126 - val_acc: 0.9657\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1539 - acc: 0.9528 - val_loss: 0.1027 - val_acc: 0.9690\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1451 - acc: 0.9553 - val_loss: 0.0968 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1413 - acc: 0.9567 - val_loss: 0.0921 - val_acc: 0.9714\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1340 - acc: 0.9581 - val_loss: 0.0955 - val_acc: 0.9700\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1290 - acc: 0.9592 - val_loss: 0.0930 - val_acc: 0.9721\n",
      "CNN Error: 2.79%\n"
     ]
    }
   ],
   "source": [
    "    # Simple CNN \n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# fix dimension ordering issue\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define a simple CNN model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (27,27), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 165s - loss: 0.2754 - acc: 0.9220 - val_loss: 0.0837 - val_acc: 0.9748\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 159s - loss: 0.0820 - acc: 0.9750 - val_loss: 0.0493 - val_acc: 0.9833\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 162s - loss: 0.0579 - acc: 0.9825 - val_loss: 0.0437 - val_acc: 0.9857\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 196s - loss: 0.0452 - acc: 0.9858 - val_loss: 0.0367 - val_acc: 0.9873\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 200s - loss: 0.0367 - acc: 0.9881 - val_loss: 0.0343 - val_acc: 0.9890\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 188s - loss: 0.0313 - acc: 0.9901 - val_loss: 0.0335 - val_acc: 0.9897\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 191s - loss: 0.0264 - acc: 0.9918 - val_loss: 0.0301 - val_acc: 0.9906\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 193s - loss: 0.0230 - acc: 0.9922 - val_loss: 0.0281 - val_acc: 0.9908\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 201s - loss: 0.0204 - acc: 0.9933 - val_loss: 0.0306 - val_acc: 0.9898\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 175s - loss: 0.0170 - acc: 0.9948 - val_loss: 0.0279 - val_acc: 0.9908\n",
      "CNN Error: 0.92%\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN \n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# fix dimension ordering issue\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define a simple CNN model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (12,12), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 168s - loss: 0.2751 - acc: 0.9206 - val_loss: 0.0927 - val_acc: 0.9727\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 171s - loss: 0.0807 - acc: 0.9761 - val_loss: 0.0477 - val_acc: 0.9850\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 165s - loss: 0.0556 - acc: 0.9832 - val_loss: 0.0408 - val_acc: 0.9862\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 170s - loss: 0.0442 - acc: 0.9859 - val_loss: 0.0358 - val_acc: 0.9877\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 173s - loss: 0.0363 - acc: 0.9882 - val_loss: 0.0374 - val_acc: 0.9872\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 173s - loss: 0.0304 - acc: 0.9902 - val_loss: 0.0328 - val_acc: 0.9897\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 165s - loss: 0.0272 - acc: 0.9912 - val_loss: 0.0316 - val_acc: 0.9884\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 162s - loss: 0.0227 - acc: 0.9924 - val_loss: 0.0317 - val_acc: 0.9896\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 163s - loss: 0.0202 - acc: 0.9933 - val_loss: 0.0335 - val_acc: 0.9886\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 164s - loss: 0.0178 - acc: 0.9938 - val_loss: 0.0305 - val_acc: 0.9897\n",
      "CNN Error: 1.03%\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN \n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# fix dimension ordering issue\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define a simple CNN model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (13,13), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 156s - loss: 0.2973 - acc: 0.9139 - val_loss: 0.0950 - val_acc: 0.9717\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 143s - loss: 0.0898 - acc: 0.9725 - val_loss: 0.0566 - val_acc: 0.9826\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 149s - loss: 0.0612 - acc: 0.9816 - val_loss: 0.0449 - val_acc: 0.9864\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 154s - loss: 0.0481 - acc: 0.9849 - val_loss: 0.0399 - val_acc: 0.9873\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 149s - loss: 0.0405 - acc: 0.9874 - val_loss: 0.0368 - val_acc: 0.9878\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 144s - loss: 0.0331 - acc: 0.9897 - val_loss: 0.0366 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 142s - loss: 0.0304 - acc: 0.9899 - val_loss: 0.0349 - val_acc: 0.9887\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 146s - loss: 0.0265 - acc: 0.9913 - val_loss: 0.0325 - val_acc: 0.9894\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 145s - loss: 0.0229 - acc: 0.9926 - val_loss: 0.0320 - val_acc: 0.9900\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 143s - loss: 0.0203 - acc: 0.9935 - val_loss: 0.0333 - val_acc: 0.9902\n",
      "CNN Error for filter =  14 : 0.98%\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 139s - loss: 0.2872 - acc: 0.9159 - val_loss: 0.0946 - val_acc: 0.9705\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 144s - loss: 0.0886 - acc: 0.9735 - val_loss: 0.0531 - val_acc: 0.9831\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 157s - loss: 0.0619 - acc: 0.9814 - val_loss: 0.0505 - val_acc: 0.9841\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 139s - loss: 0.0486 - acc: 0.9848 - val_loss: 0.0394 - val_acc: 0.9874\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 143s - loss: 0.0416 - acc: 0.9873 - val_loss: 0.0394 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 143s - loss: 0.0343 - acc: 0.9892 - val_loss: 0.0363 - val_acc: 0.9881\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 141s - loss: 0.0302 - acc: 0.9902 - val_loss: 0.0313 - val_acc: 0.9893\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 142s - loss: 0.0266 - acc: 0.9914 - val_loss: 0.0327 - val_acc: 0.9893\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 145s - loss: 0.0231 - acc: 0.9929 - val_loss: 0.0368 - val_acc: 0.9881\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 146s - loss: 0.0217 - acc: 0.9925 - val_loss: 0.0322 - val_acc: 0.9905\n",
      "CNN Error for filter =  15 : 0.95%\n"
     ]
    }
   ],
   "source": [
    "# define a simple CNN model\n",
    "def baseline_model(i):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (i,i), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "for i in range(14,16):\n",
    "    # build the modela\n",
    "    model = baseline_model(i)\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "    # Final evaluation of the model\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"CNN Error for filter = \",i,\": %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 87s - loss: 0.3652 - acc: 0.8939 - val_loss: 0.1321 - val_acc: 0.9611\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 90s - loss: 0.1347 - acc: 0.9595 - val_loss: 0.0998 - val_acc: 0.9697\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 87s - loss: 0.0956 - acc: 0.9706 - val_loss: 0.0692 - val_acc: 0.9788\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 78s - loss: 0.0765 - acc: 0.9762 - val_loss: 0.0591 - val_acc: 0.9798\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 78s - loss: 0.0649 - acc: 0.9795 - val_loss: 0.0560 - val_acc: 0.9826\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 79s - loss: 0.0569 - acc: 0.9822 - val_loss: 0.0515 - val_acc: 0.9844\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 71s - loss: 0.0501 - acc: 0.9840 - val_loss: 0.0583 - val_acc: 0.9804\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 77s - loss: 0.0451 - acc: 0.9856 - val_loss: 0.0450 - val_acc: 0.9852\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 78s - loss: 0.0405 - acc: 0.9872 - val_loss: 0.0435 - val_acc: 0.9860\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 78s - loss: 0.0361 - acc: 0.9884 - val_loss: 0.0448 - val_acc: 0.9847\n",
      "CNN Error for filter =  20 : 1.53%\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 75s - loss: 0.3520 - acc: 0.8960 - val_loss: 0.1245 - val_acc: 0.9599\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 75s - loss: 0.1207 - acc: 0.9632 - val_loss: 0.0772 - val_acc: 0.9766\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 74s - loss: 0.0871 - acc: 0.9737 - val_loss: 0.0621 - val_acc: 0.9802\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 78s - loss: 0.0681 - acc: 0.9788 - val_loss: 0.0568 - val_acc: 0.9824\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 74s - loss: 0.0596 - acc: 0.9815 - val_loss: 0.0471 - val_acc: 0.9850\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 71s - loss: 0.0513 - acc: 0.9836 - val_loss: 0.0462 - val_acc: 0.9852\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 72s - loss: 0.0461 - acc: 0.9854 - val_loss: 0.0446 - val_acc: 0.9850\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 79s - loss: 0.0401 - acc: 0.9874 - val_loss: 0.0438 - val_acc: 0.9863\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 76s - loss: 0.0369 - acc: 0.9877 - val_loss: 0.0391 - val_acc: 0.9888\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 79s - loss: 0.0336 - acc: 0.9891 - val_loss: 0.0410 - val_acc: 0.9869\n",
      "CNN Error for filter =  21 : 1.31%\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 61s - loss: 0.3824 - acc: 0.8874 - val_loss: 0.1361 - val_acc: 0.9591\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 59s - loss: 0.1373 - acc: 0.9589 - val_loss: 0.0876 - val_acc: 0.9724\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 59s - loss: 0.1000 - acc: 0.9689 - val_loss: 0.0650 - val_acc: 0.9802\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 59s - loss: 0.0781 - acc: 0.9758 - val_loss: 0.0631 - val_acc: 0.9794\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 59s - loss: 0.0666 - acc: 0.9789 - val_loss: 0.0539 - val_acc: 0.9812\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 61s - loss: 0.0611 - acc: 0.9804 - val_loss: 0.0476 - val_acc: 0.9853\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 59s - loss: 0.0546 - acc: 0.9827 - val_loss: 0.0483 - val_acc: 0.9850\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 60s - loss: 0.0485 - acc: 0.9843 - val_loss: 0.0441 - val_acc: 0.9862\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 61s - loss: 0.0441 - acc: 0.9858 - val_loss: 0.0461 - val_acc: 0.9848\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 63s - loss: 0.0417 - acc: 0.9867 - val_loss: 0.0467 - val_acc: 0.9856\n",
      "CNN Error for filter =  22 : 1.44%\n"
     ]
    }
   ],
   "source": [
    "# define a simple CNN model\n",
    "def baseline_model(i):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (i,i), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "for i in range(20,23):\n",
    "    # build the modela\n",
    "    model = baseline_model(i)\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "    # Final evaluation of the model\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"CNN Error for filter = \",i,\": %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 312s - loss: 0.4636 - acc: 0.8690 - val_loss: 0.2655 - val_acc: 0.9208\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 352s - loss: 0.2496 - acc: 0.9237 - val_loss: 0.1916 - val_acc: 0.9421\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 349s - loss: 0.1896 - acc: 0.9424 - val_loss: 0.1652 - val_acc: 0.9473\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 346s - loss: 0.1530 - acc: 0.9523 - val_loss: 0.1429 - val_acc: 0.9572\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 349s - loss: 0.1290 - acc: 0.9598 - val_loss: 0.1183 - val_acc: 0.9636\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 346s - loss: 0.1116 - acc: 0.9652 - val_loss: 0.1103 - val_acc: 0.9664\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 348s - loss: 0.0992 - acc: 0.9688 - val_loss: 0.0987 - val_acc: 0.9709\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 320s - loss: 0.0892 - acc: 0.9721 - val_loss: 0.0950 - val_acc: 0.9683\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 336s - loss: 0.0824 - acc: 0.9741 - val_loss: 0.0919 - val_acc: 0.9709\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 337s - loss: 0.0758 - acc: 0.9763 - val_loss: 0.0944 - val_acc: 0.9700\n",
      "CNN Error for filter =  1 : 3.00%\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 289s - loss: 0.3043 - acc: 0.9139 - val_loss: 0.1323 - val_acc: 0.9613\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 294s - loss: 0.1096 - acc: 0.9680 - val_loss: 0.0793 - val_acc: 0.9760\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2169s - loss: 0.0759 - acc: 0.9774 - val_loss: 0.0613 - val_acc: 0.9813\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 293s - loss: 0.0595 - acc: 0.9822 - val_loss: 0.0584 - val_acc: 0.9820\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 320s - loss: 0.0489 - acc: 0.9853 - val_loss: 0.0523 - val_acc: 0.9836\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 316s - loss: 0.0413 - acc: 0.9875 - val_loss: 0.0497 - val_acc: 0.9840\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 299s - loss: 0.0331 - acc: 0.9901 - val_loss: 0.0505 - val_acc: 0.9836\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 300s - loss: 0.0300 - acc: 0.9905 - val_loss: 0.0439 - val_acc: 0.9858\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 297s - loss: 0.0250 - acc: 0.9921 - val_loss: 0.0478 - val_acc: 0.9852\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 299s - loss: 0.0223 - acc: 0.9930 - val_loss: 0.0435 - val_acc: 0.9853\n",
      "CNN Error for filter =  2 : 1.47%\n"
     ]
    }
   ],
   "source": [
    "# define a simple CNN model\n",
    "def baseline_model(i):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (i,i), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "for i in range(1,3):\n",
    "    # build the modela\n",
    "    model = baseline_model(i)\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "    # Final evaluation of the model\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"CNN Error for filter = \",i,\": %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 488s - loss: 0.2496 - acc: 0.9280 - val_loss: 0.0801 - val_acc: 0.9757\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 408s - loss: 0.0745 - acc: 0.9776 - val_loss: 0.0489 - val_acc: 0.9842\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 407s - loss: 0.0519 - acc: 0.9841 - val_loss: 0.0428 - val_acc: 0.9875\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 408s - loss: 0.0421 - acc: 0.9867 - val_loss: 0.0395 - val_acc: 0.9874\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 569s - loss: 0.0329 - acc: 0.9896 - val_loss: 0.0320 - val_acc: 0.9888\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 211s - loss: 0.0278 - acc: 0.9915 - val_loss: 0.0328 - val_acc: 0.9899\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 214s - loss: 0.0235 - acc: 0.9926 - val_loss: 0.0285 - val_acc: 0.9911\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 213s - loss: 0.0203 - acc: 0.9933 - val_loss: 0.0270 - val_acc: 0.9905\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 224s - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0273 - val_acc: 0.9901\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 219s - loss: 0.0147 - acc: 0.9951 - val_loss: 0.0281 - val_acc: 0.9910\n",
      "CNN Error: 0.90%\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN \n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# fix dimension ordering issue\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define a simple CNN model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (8, 8), input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,5,7,8,11,12,13,14,15,20,21,22,27])\n",
    "y = np.array([300,147,99,82,90,96,92,103,98,95,153,131,144,279])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.988212 -25.331876 243.003637]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec89853278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.interpolate import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "p1 = np.polyfit(x,y,1)\n",
    "p2 = np.polyfit(x,y,2)\n",
    "p3 = np.polyfit(x,y,3)\n",
    "p4 = np.polyfit(x,y,4)\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "plt.plot(x,y,'o')\n",
    "#plt.plot(x,np.polyval(p1,x),'r--')\n",
    "#plt.plot(x,np.polyval(p2,x),'b-')    #p2 and p3 are overlapping\n",
    "#plt.plot(x,np.polyval(p3,x),'m:')\n",
    "plt.plot(x,np.polyval(p4,x),'g-')\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.033119830654873922, -1.4837444975833169, 21.206362750046807, -91.046734144418124]\n",
      "[ 18.47618028+2.99343409j  18.47618028-2.99343409j   7.84691734+0.j        ]\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "l.append(4*p4[0])\n",
    "l.append(3*p4[1])\n",
    "l.append(2*p4[2])\n",
    "l.append(p4[3])\n",
    "print(l)\n",
    "\n",
    "roots = np.roots(l)\n",
    "print(roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.008280, -0.494581, 10.603181, -91.046734, 343.338629])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.806101764162293"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p4[0]*(7**4))+(p4[1]*(7**3))+(p4[2]*(7**2))+(p4[3]*(7))+p4[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension  error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dimension  error\n",
       "1               3.00\n",
       "2               1.47\n",
       "5               0.99\n",
       "7               0.82\n",
       "11              0.96\n",
       "12              0.92\n",
       "13              1.03\n",
       "14              0.98\n",
       "15              0.95\n",
       "20              1.53\n",
       "21              1.31\n",
       "22              1.44\n",
       "27              2.79"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.txt\",delimiter=\"\\t\\t\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
